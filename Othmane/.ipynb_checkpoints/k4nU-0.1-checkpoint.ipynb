{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import darc_core\n",
    "import sys\n",
    "import hashlib as hs\n",
    "import base64 as b64\n",
    "import os\n",
    "import random as rd\n",
    "import datetime as dt\n",
    "from darc_core.metrics import Metrics\n",
    "from darc_core.preprocessing import round1_preprocessing\n",
    "from darc_core.utils import check_format_trans_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.4 s, sys: 566 ms, total: 24 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"./ground_truth.csv\", parse_dates=[\"date\"])\n",
    "df[\"hours\"]= pd.to_datetime(df[\"hours\"], format = '%H:%M%S').dt.hour\n",
    "df[\"month\"]=df[\"date\"].dt.month\n",
    "df[\"year\"]=df[\"date\"].dt.year\n",
    "df[\"id_user\"]=df[\"id_user\"].astype(str)\n",
    "df[\"price\"]=df[\"price\"].astype(\"float\")\n",
    "df[\"qty\"]=df[\"qty\"].astype(\"float\")\n",
    "df_dict = df.T.to_dict('list')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min, sys: 990 ms, total: 2min 1s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def mergeIdentical(df,df_dict):\n",
    "    \"\"\" Merge \"same\" transaction into one line. Assign \"DEL\" to duplicates\n",
    "        Transactions are \"identical\" if their keys are equal\n",
    "        \n",
    "        :map: key:[id_user,date,id_item] value:[qty_cumulative,count]\n",
    "    \"\"\"\n",
    "    map={}\n",
    "    for d in range(0,len(df)):\n",
    "        if(map.get((df[\"id_user\"][d],df[\"date\"][d],df[\"id_item\"][d]))):\n",
    "            df_dict[d][0]=\"DEL\"\n",
    "            df_dict[d][1]=df_dict[d][1].strftime(\"%Y-%m-01\")\n",
    "            df_dict[d][2]=\"\"\n",
    "            df_dict[d][3]=\"\"\n",
    "            df_dict[d][4]=\"\"\n",
    "            df_dict[d][5]=\"\"\n",
    "        else:\n",
    "            map[(df[\"id_user\"][d],df[\"date\"][d],df[\"id_item\"][d])]=[df.loc[d][\"qty\"],1]\n",
    "    \n",
    "    dfn = pd.DataFrame.from_dict(df_dict,orient=\"index\")\n",
    "    dfn = dfn.rename(columns={0:\"id_user\",1:\"date\",2:\"hours\",3:\"id_item\",4:\"price\",5:\"qty\",6:\"month\",7:\"year\"})\n",
    "    return dfn,map\n",
    "\n",
    "dfn,map=mergeIdentical(df,df_dict)\n",
    "save_dfn_merge=dfn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, partition, column): \n",
    "    \"\"\"\n",
    "        Split df[partition] over column on median \n",
    "        :return: List[[IndexRange]]*2 {left ,right}\n",
    "    \"\"\"\n",
    "    dfp = df[\"id_user\"][partition]\n",
    "    sanitizedPartition = dfp.index[dfp != \"DEL\"]\n",
    "    dfp = df[column][sanitizedPartition]\n",
    "    if (column in categorical):\n",
    "        values = dfp.unique()\n",
    "        dfp.sort_values(inplace=True)\n",
    "        lv=set(values[:len(values)//2])\n",
    "        rv=set(values[len(values)//2:])\n",
    "        return dfp.index[dfp.isin(lv)],dfp.index[dfp.isin(rv)]\n",
    "    else:\n",
    "        median=dfp.median()\n",
    "        dfp.sort_values(inplace=True)\n",
    "        dfl=dfp.index[dfp<median]\n",
    "        dfr=dfp.index[dfp>=median]\n",
    "        return(dfl,dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_k_anonymous (df, partition, k=1):\n",
    "    if ((len(partition)<k)):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 47s, sys: 4.45 s, total: 11min 52s\n",
      "Wall time: 11min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfn[\"id_item\"]=dfn[\"id_item\"].astype(\"category\")\n",
    "categorical = set ({'id_item'})\n",
    "def partition_dataset(df, is_valid):\n",
    "    \"\"\"\n",
    "        Greedy search\n",
    "        Split dataframe over {year,month,id_item} \n",
    "        :return: List[[IndexRange]] \n",
    "    \"\"\"\n",
    "    finished_partitions=[]\n",
    "    partitions=[df.index]\n",
    "    while partitions:    \n",
    "        partition = partitions.pop(0)\n",
    "        columns = [\"year\",\"month\", \"id_item\"]\n",
    "        for column in columns:\n",
    "            lp, rp = split(df,partition,column)\n",
    "            if not is_valid(df,lp) or not is_valid(df,rp):\n",
    "                continue\n",
    "            partitions.extend((lp,rp))\n",
    "            break\n",
    "        else:\n",
    "            finished_partitions.append(partition)\n",
    "    return finished_partitions\n",
    "finished_partitions = partition_dataset(dfn, is_k_anonymous)\n",
    "save_finished_partitions=finished_partitions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 40s, sys: 34.2 s, total: 32min 14s\n",
      "Wall time: 33min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfn[\"id_item\"]=dfn[\"id_item\"].astype(\"category\")\n",
    "categorical = set ({'id_item'})\n",
    "finished_partitions=save_finished_partitions\n",
    "def make_l_diverse(df,partitions,l=9):\n",
    "    \"\"\"\n",
    "         DEL partitions with l-diversity < l\n",
    "    \"\"\"\n",
    "    i=0\n",
    "    filtered=[]\n",
    "    while(len(partitions)):\n",
    "        if (df.loc[partitions[0],\"id_user\"].nunique()<l):\n",
    "            df.loc[partitions[0],\"id_user\"]=\"DEL\"\n",
    "            if(isinstance(df.loc[partitions[0],[\"date\"]].squeeze(),dt.date)):\n",
    "                df.loc[partitions[0],[\"date\"]]=df.loc[partitions[0],[\"date\"]].squeeze().strftime('%Y-%m-01')\n",
    "            else:\n",
    "                df.loc[partitions[0],[\"date\"]]=df.loc[partitions[0],[\"date\"]].squeeze().apply(lambda x: x.strftime('%Y-%m-01'))\n",
    "            df.loc[partitions[0],[\"hours\",\"id_item\",\"price\",\"qty\",]]=\"\" \n",
    "            partitions.pop(0)           \n",
    "        else:\n",
    "            filtered.append(partitions.pop(0))       \n",
    "    return dfn, filtered\n",
    "dfn, finished_partitions = make_l_diverse(dfn,finished_partitions)\n",
    "save_diversity=finished_partitions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleDates(df,partition):\n",
    "    \"\"\"\n",
    "         For same partition, swap {dates,qty} randomly.\n",
    "    \"\"\"\n",
    "    date_array=df.loc[partition,\"date\"].copy().squeeze()\n",
    "    qty_array=df.loc[partition,\"qty\"].copy().squeeze()\n",
    "    date_array.reset_index(drop=True,inplace=True) \n",
    "    qty_array.reset_index(drop=True,inplace=True)\n",
    "    date_shuffled=[]\n",
    "    qty_shuffled=[]\n",
    "    while(len(date_array)):\n",
    "        i=rd.randrange(len(date_array))\n",
    "        date_shuffled.append(date_array[i])\n",
    "        date_array.drop(i,inplace=True)\n",
    "        date_array.reset_index(drop=True,inplace=True)\n",
    "        qty_shuffled.append(qty_array[i])\n",
    "        qty_array.drop(i,inplace=True)\n",
    "        qty_array.reset_index(drop=True,inplace=True)\n",
    "    df.loc[partition,\"date\"]=date_shuffled\n",
    "    df.loc[partition,\"qty\"]=qty_shuffled\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def build_anonymized_dataset(df,partitions):\n",
    "    \"\"\"\n",
    "        Generalization of Columns {dates,qty,hours}\n",
    "    \"\"\"\n",
    "    for p in partitions:\n",
    "        df.loc[p,[\"hours\"]]=df.loc[p,[\"hours\"]].mean().values[0]\n",
    "        df=shuffleDates(df,p)\n",
    "    return df\n",
    "dfn=build_anonymized_dataset(dfn,finished_partitions)\n",
    "save_dfn=dfn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dfn.id_user=dfn.id_user.astype(str)\n",
    "dfn_copy=dfn.copy()\n",
    "\n",
    "def generateSalts():\n",
    "    \"\"\" \n",
    "        Generate Salt{256b} Table : Mij = Salt for user i in month j \n",
    "    \"\"\"\n",
    "    # Set of {1..12} (number of the month)\n",
    "    ordered_months = list(range(1,13))\n",
    "    # Set of all unique user's IDs\n",
    "    ids = dfn_copy[\"id_user\"].unique()\n",
    "    ids = ids[ids != \"DEL\"]\n",
    "    # Generate salt table\n",
    "    salt_table=pd.DataFrame(columns=ordered_months,index=ids)\n",
    "    salt_table.set_index(ids,inplace=True)\n",
    "    for i in ids:\n",
    "        for j in ordered_months:\n",
    "            #Â Generates unique b64 values\n",
    "            salt_table[j][i]=os.urandom(256)\n",
    "    return salt_table\n",
    "\n",
    "salt_table = generateSalts()\n",
    "salt_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashme(id_user, month): \n",
    "    \"\"\"\n",
    "        :return: Hash[user,month] = SHA256(Salt[user,month] + id_user)\n",
    "    \"\"\"\n",
    "    if(id_user==\"DEL\"):\n",
    "        return id_user\n",
    "    else:\n",
    "        hashme.counter+=1\n",
    "        percent=(hashme.counter/307054)*100 \n",
    "        sys.stdout.write(\"\\rProgress %i -- Count : %i / 307054\" % (percent,hashme.counter))\n",
    "        sys.stdout.flush()\n",
    "        return hs.sha256(salt_table.loc[[id_user],month][0] + id_user.encode()).hexdigest()\n",
    "#Static Counter for ProgressBar\n",
    "hashme.counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def doHash():\n",
    "    \"\"\"\n",
    "        Apply hashme for all rows\n",
    "    \"\"\"\n",
    "    dfn_copy.sort_values([\"id_user\",\"month\"])\n",
    "    salt_table.sort_index(inplace=True)\n",
    "    dfn[\"id_user\"]=dfn_copy.apply(lambda x: hashme(x[\"id_user\"],x[\"month\"]), axis=1)\n",
    "doHash()\n",
    "hash_dfn=dfn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def hour_to_int(hours):\n",
    "    if(isinstance(hours,float)):\n",
    "        return int(hours)\n",
    "def parse_dates(date):\n",
    "    if(isinstance(date,dt.date) and not pd.isnull(date)):\n",
    "        return date.strftime('%Y/%m/%d')\n",
    "dfn[\"qty\"]=df[\"qty\"].astype(\"int\")\n",
    "dfn[\"price\"]=df[\"price\"].round(2)\n",
    "dfn[\"date\"]=dfn.apply(lambda x: parse_dates(x[\"date\"]),axis=1)\n",
    "dfn[\"hours\"]=dfn.apply(lambda x: hour_to_int(x[\"hours\"]), axis=1)\n",
    "dfn.drop([\"month\",\"year\"],axis=1,inplace=True)\n",
    "dfn.sort_values([\"date\"],inplace=True)\n",
    "dfn.to_csv(\"./atx1.csv\",index=False)\n",
    "dfa=pd.read_csv(\"./atx1.csv\")\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ground_truth, submission = round1_preprocessing(\n",
    "    \"./ground_truth.csv\", \"./atx1.csv\"\n",
    ")\n",
    "check_format_trans_file(ground_truth, submission)\n",
    "metric = Metrics(ground_truth, submission)\n",
    "scores = metric.scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
